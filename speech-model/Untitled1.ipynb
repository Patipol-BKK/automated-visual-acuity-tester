{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54525a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import scipy\n",
    "import scipy.io.wavfile as wav\n",
    "import numpy as np\n",
    "import wave\n",
    "import matplotlib.pyplot as plt\n",
    "import noisereduce\n",
    "import speechpy\n",
    "import os\n",
    "from scipy.cluster.vq import vq, kmeans2, kmeans, whiten\n",
    "from scipy.spatial import distance\n",
    "from tqdm.notebook import tqdm\n",
    "from hmmlearn import hmm\n",
    "import ruptures as rpt\n",
    "from matplotlib.ticker import (MultipleLocator, AutoMinorLocator)\n",
    "import soundfile as sf\n",
    "import sounddevice as sd\n",
    "import pickle \n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "import random\n",
    "import pyaudio\n",
    "from scipy.io.wavfile import write\n",
    "from sklearn.utils import shuffle\n",
    "import librosa\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79189689",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db464890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training phoneme signals hasn't been loaded yet\n",
      "testing phoneme signals hasn't been loaded yet\n"
     ]
    }
   ],
   "source": [
    "testing_dir = os.getcwd()\n",
    "testing_dir = os.path.join(testing_dir, '.\\\\TIMIT\\\\TEST')\n",
    "\n",
    "training_dir = os.getcwd()\n",
    "training_dir = os.path.join(training_dir, '.\\\\TIMIT\\\\TRAIN')\n",
    "\n",
    "\n",
    "\n",
    "def load_phoneme_dataset(working_dir):\n",
    "    phoneme_signals = {}\n",
    "    dialect_folders = os.listdir(working_dir)\n",
    "    for dialect_folder in tqdm(dialect_folders, leave=False):\n",
    "        voice_folders = os.listdir(os.path.join(working_dir, dialect_folder))\n",
    "        for voice_sample_folder in tqdm(voice_folders, leave=False):\n",
    "            current_dir = os.path.join(working_dir, dialect_folder)\n",
    "            current_dir = os.path.join(current_dir, voice_sample_folder)\n",
    "\n",
    "            voice_samples = [file for file in os.listdir(current_dir) if file.endswith('.WAV')]\n",
    "            for voice_sample in voice_samples:\n",
    "                voice_sample_path = os.path.join(current_dir, voice_sample)\n",
    "                signal, fs = sf.read(voice_sample_path)\n",
    "#                 signal = np.zeros_like(signal)\n",
    "#                 signal[40000] = 10\n",
    "#                 print(signal.shape)\n",
    "    \n",
    "                # Pre-emphasize signal\n",
    "                signal_preemphasized = speechpy.processing.preemphasis(signal, cof=0.98)\n",
    "\n",
    "                # FFT\n",
    "#                 frames = speechpy.processing.stack_frames(signal_preemphasized, sampling_frequency=fs, frame_length=0.02, frame_stride=0.01, zero_padding=True)\n",
    "#                 fft = speechpy.processing.fft_spectrum(frames, 256)\n",
    "    \n",
    "#                 fig, ax = plt.subplots(nrows=2, ncols=1, constrained_layout=True)\n",
    "#                 fig.supxlabel('Time')\n",
    "#                 fig.set_size_inches(15, 10)\n",
    "#                 ax[0].plot(signal_preemphasized)\n",
    "#                 ax[0].set_xlim(0, signal_preemphasized.shape[0])\n",
    "                \n",
    "#                 fig.colorbar(ax[1].pcolor(fft.T))\n",
    "                \n",
    "\n",
    "                phoneme_transcript_path = os.path.join(current_dir, voice_sample)[:-3] + 'PHN'\n",
    "                f = open(phoneme_transcript_path, encoding='utf-8')\n",
    "                lines = f.readlines()\n",
    "                for line in lines:\n",
    "                    data = line.split(' ')\n",
    "                    phoneme_start_idx = int(data[0])\n",
    "                    phoneme_stop_idx = int(data[1])\n",
    "                    phoneme = data[2].strip()\n",
    "                    \n",
    "#                     ax[0].axvline(x=phoneme_start_idx, color='red')\n",
    "#                     ax[1].axvline(x=phoneme_start_idx/160, color='red')\n",
    "                    \n",
    "                    phoneme_signal_preemphasized = signal_preemphasized[int(phoneme_start_idx):int(phoneme_stop_idx)]\n",
    "\n",
    "                \n",
    "                    if phoneme in phoneme_signals:\n",
    "#                         print(phoneme_fft)\n",
    "                        phoneme_signals[phoneme].append(phoneme_signal_preemphasized)\n",
    "                        \n",
    "                    else:\n",
    "                        phoneme_signals[phoneme] = []\n",
    "                        phoneme_signals[phoneme].append(phoneme_signal_preemphasized)\n",
    "#                     print(phoneme_signals[phoneme])\n",
    "    return fs, phoneme_signals\n",
    "\n",
    "try:\n",
    "    training_phoneme_signals\n",
    "except NameError:\n",
    "    print('training phoneme signals hasn\\'t been loaded yet')\n",
    "    try:\n",
    "        with open('training_phoneme_signals.pkl', 'rb') as handle:\n",
    "            training_phoneme_signals = pickle.load(handle)\n",
    "    except:\n",
    "        print('training_phoneme_signals.pkl not found, start loading dataset')\n",
    "        fs, training_phoneme_signals = load_phoneme_dataset(training_dir)\n",
    "        with open('training_phoneme_signals.pkl', 'wb') as handle:\n",
    "            pickle.dump(training_phoneme_signals, handle)\n",
    "            \n",
    "try:\n",
    "    testing_phoneme_signals\n",
    "except NameError:\n",
    "    print('testing phoneme signals hasn\\'t been loaded yet')\n",
    "    try:\n",
    "        with open('testing_phoneme_signals.pkl', 'rb') as handle:\n",
    "            testing_phoneme_signals = pickle.load(handle)\n",
    "    except:\n",
    "        print('testing_phoneme_signals.pkl not found, start loading dataset')\n",
    "        fs, testing_phoneme_signals = load_phoneme_dataset(testing_dir)\n",
    "        with open('testing_phoneme_signals.pkl', 'wb') as handle:\n",
    "            pickle.dump(testing_phoneme_signals, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d32d92f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['h#', 'sh', 'ix', 'hv', 'eh', 'dcl', 'jh', 'ih', 'd', 'ah', 'kcl', 'k', 's', 'ux', 'q', 'en', 'gcl', 'g', 'r', 'w', 'ao', 'epi', 'dx', 'axr', 'l', 'y', 'uh', 'n', 'ae', 'm', 'oy', 'ax', 'dh', 'tcl', 'iy', 'v', 'f', 't', 'pcl', 'ow', 'hh', 'ch', 'bcl', 'b', 'aa', 'em', 'ng', 'ay', 'th', 'ax-h', 'ey', 'p', 'aw', 'er', 'nx', 'z', 'el', 'uw', 'pau', 'zh', 'eng'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_phoneme_signals.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f1d22d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['s', 's'], ['i', 'iy'], ['i', 'ih'], ['d', 'd'], ['h', 'hh'], ['e', 'eh'], ['e', 'ay'], ['ch', 'ch'], ['k', 'k'], ['n', 'n'], ['o', 'ow'], ['a', 'ah'], ['r', 'r'], ['v', 'v'], ['z', 'z'], ['silence', 'h#'], ['other', 'sh'], ['other', 'ix'], ['other', 'hv'], ['other', 'dcl'], ['other', 'jh'], ['other', 'kcl'], ['other', 'ux'], ['other', 'q'], ['other', 'en'], ['other', 'gcl'], ['other', 'g'], ['other', 'w'], ['other', 'ao'], ['other', 'epi'], ['other', 'dx'], ['other', 'axr'], ['other', 'l'], ['other', 'y'], ['other', 'uh'], ['other', 'ae'], ['other', 'm'], ['other', 'oy'], ['other', 'ax'], ['other', 'dh'], ['other', 'tcl'], ['other', 'f'], ['other', 't'], ['other', 'pcl'], ['other', 'bcl'], ['other', 'b'], ['other', 'aa'], ['other', 'em'], ['other', 'ng'], ['other', 'th'], ['other', 'ax-h'], ['other', 'ey'], ['other', 'p'], ['other', 'aw'], ['other', 'er'], ['other', 'nx'], ['other', 'el'], ['other', 'uw'], ['other', 'pau'], ['other', 'zh'], ['other', 'eng']] \n",
      "\n",
      "['s', 'i', 'd', 'h', 'e', 'ch', 'k', 'n', 'o', 'a', 'r', 'v', 'z', 'silence', 'other']\n"
     ]
    }
   ],
   "source": [
    "keywords_list = [\n",
    "    ['s', 's'],\n",
    "    ['i', 'iy'],\n",
    "    ['i', 'ih'],\n",
    "    ['d', 'd'],\n",
    "    ['h', 'hh'],\n",
    "    ['e', 'eh'],\n",
    "    ['e', 'ay'],\n",
    "    ['ch', 'ch'],\n",
    "    ['k', 'k'],\n",
    "    ['n', 'n'],\n",
    "    ['o', 'ow'],\n",
    "    ['a', 'ah'],\n",
    "    ['r', 'r'],\n",
    "    ['v', 'v'],\n",
    "    ['z', 'z'],\n",
    "    ['silence', 'h#'],\n",
    "]\n",
    "\n",
    "for key in training_phoneme_signals.keys():\n",
    "    found = False\n",
    "    for phoneme_pair in keywords_list:\n",
    "        if phoneme_pair[1] == key:\n",
    "            found = True\n",
    "        if found:\n",
    "            break\n",
    "    \n",
    "    if not found:\n",
    "        keywords_list.append(['other', key])\n",
    "print(keywords_list, '\\n')\n",
    "\n",
    "unique_keywords = []\n",
    "for phoneme_pair in keywords_list:\n",
    "    if phoneme_pair[0] not in unique_keywords:\n",
    "        unique_keywords.append(phoneme_pair[0])\n",
    "print(unique_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6a218f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_signal_array(signal_array):\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, constrained_layout=True)\n",
    "    fig.supxlabel('Time')\n",
    "    fig.set_size_inches(15, 5)\n",
    "    ax.plot(signal_array)\n",
    "    \n",
    "def plot_pcolor(signal_array):\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, constrained_layout=True)\n",
    "    fig.supxlabel('Time')\n",
    "    fig.set_size_inches(15, 5)\n",
    "    ax.pcolor(signal_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8f254f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ba4b27686da450aa4091dbf476af2bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0829cdd837574975bb3605a5f7d27129",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63440\n",
      "58000\n",
      "79520\n",
      "56160\n",
      "60000\n",
      "52960\n",
      "49520\n",
      "56560\n",
      "53680\n",
      "39120\n",
      "84400\n",
      "66480\n",
      "70640\n",
      "73520\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "testing_dir = os.getcwd()\n",
    "testing_dir = os.path.join(testing_dir, '.\\\\TIMIT\\\\TEST')\n",
    "\n",
    "training_dir = os.getcwd()\n",
    "training_dir = os.path.join(training_dir, '.\\\\TIMIT\\\\TRAIN')\n",
    "\n",
    "\n",
    "\n",
    "def create_phoneme_dataset(working_dir, prev_frames, future_frames):\n",
    "    signals_list = []\n",
    "    labels_list = []\n",
    "    dialect_folders = os.listdir(working_dir)\n",
    "    for dialect_folder in tqdm(dialect_folders, leave=False):\n",
    "        voice_folders = os.listdir(os.path.join(working_dir, dialect_folder))\n",
    "        for voice_sample_folder in tqdm(voice_folders, leave=False):\n",
    "            current_dir = os.path.join(working_dir, dialect_folder)\n",
    "            current_dir = os.path.join(current_dir, voice_sample_folder)\n",
    "\n",
    "            voice_samples = [file for file in os.listdir(current_dir) if file.endswith('.WAV')]\n",
    "            for voice_sample in voice_samples:\n",
    "                voice_sample_path = os.path.join(current_dir, voice_sample)\n",
    "                signal, fs = sf.read(voice_sample_path)\n",
    "\n",
    "                # Pre-emphasize signal\n",
    "#                 signal_preemphasized = speechpy.processing.preemphasis(signal, cof=0.98)\n",
    "            \n",
    "#                 mfcc = speechpy.feature.mfcc(signal, sampling_frequency=fs, frame_length=0.025, frame_stride=0.01,\n",
    "#                                  num_filters=40, fft_length=256, low_frequency=0, high_frequency=None)\n",
    "\n",
    "                current_signals_list = []\n",
    "                current_labels_list = []\n",
    "                phoneme_transcript_path = os.path.join(current_dir, voice_sample)[:-3] + 'PHN'\n",
    "                f = open(phoneme_transcript_path, encoding='utf-8')\n",
    "                lines = f.readlines()\n",
    "                for line in lines:\n",
    "                    data = line.split(' ')\n",
    "                    phoneme_start_idx = int(data[0])\n",
    "                    phoneme_stop_idx = int(data[1])\n",
    "                    phoneme = data[2].strip()\n",
    "                    \n",
    "                    label = np.zeros(len(unique_keywords))\n",
    "                    for phoneme_pair in keywords_list:\n",
    "                        if phoneme_pair[1] == phoneme:\n",
    "                            phoneme = phoneme_pair[0]\n",
    "                            break\n",
    "                    label[unique_keywords.index(phoneme)] = 1\n",
    "                    \n",
    "                    for frame in signal[int(phoneme_start_idx):int(phoneme_stop_idx)]:\n",
    "                        current_signals_list.append(frame)\n",
    "                        current_labels_list.append(label)\n",
    "                print(len(current_signals_list))\n",
    "                for i in range(len(current_signals_list)):\n",
    "                    if i >= prev_frames and i < len(current_signals_list) - future_frames:\n",
    "#                         if i%100:\n",
    "#                             filename = f'./local_recordings/{unique_keywords[current_labels_list[i].tolist().index(1)]}-{datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")}.wav'\n",
    "#                             sf.write(filename, current_signals_list[i - prev_frames: i + future_frames + 1], 16000)\n",
    "                        signals_list.append(current_signals_list[i - prev_frames: i + future_frames + 1])\n",
    "                        labels_list.append(unique_keywords[current_labels_list[i].tolist().index(1)])\n",
    "                        \n",
    "    return fs, signals_list, labels_list\n",
    "\n",
    "fs, x_train_signal, y_train_signal = create_phoneme_dataset(testing_dir, 30*160, 10*160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97135e2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

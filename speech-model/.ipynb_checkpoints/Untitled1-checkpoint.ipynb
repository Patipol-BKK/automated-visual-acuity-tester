{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64c7c776",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import scipy\n",
    "import scipy.io.wavfile as wav\n",
    "import numpy as np\n",
    "import wave\n",
    "import matplotlib.pyplot as plt\n",
    "import noisereduce\n",
    "import speechpy\n",
    "import os\n",
    "from scipy.cluster.vq import vq, kmeans2, kmeans, whiten\n",
    "from scipy.spatial import distance\n",
    "from tqdm.notebook import tqdm\n",
    "from hmmlearn import hmm\n",
    "import ruptures as rpt\n",
    "from matplotlib.ticker import (MultipleLocator, AutoMinorLocator)\n",
    "import soundfile as sf\n",
    "import sounddevice as sd\n",
    "import pickle \n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "import random\n",
    "import pyaudio\n",
    "from scipy.io.wavfile import write\n",
    "from sklearn.utils import shuffle\n",
    "import librosa\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae2fc8d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9da28f43ef604ed699947e99e01c2147",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e60ac55715b4dce86ff9f84a82d3b49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "testing_dir = os.getcwd()\n",
    "testing_dir = os.path.join(testing_dir, '.\\\\TIMIT\\\\TEST')\n",
    "\n",
    "training_dir = os.getcwd()\n",
    "training_dir = os.path.join(training_dir, '.\\\\TIMIT\\\\TRAIN')\n",
    "\n",
    "\n",
    "\n",
    "def create_phoneme_dataset(working_dir, prev_frames, future_frames):\n",
    "    signals_list = []\n",
    "    labels_list = []\n",
    "    dialect_folders = os.listdir(working_dir)\n",
    "    for dialect_folder in tqdm(dialect_folders, leave=False):\n",
    "        voice_folders = os.listdir(os.path.join(working_dir, dialect_folder))\n",
    "        for voice_sample_folder in tqdm(voice_folders, leave=False):\n",
    "            current_dir = os.path.join(working_dir, dialect_folder)\n",
    "            current_dir = os.path.join(current_dir, voice_sample_folder)\n",
    "\n",
    "            voice_samples = [file for file in os.listdir(current_dir) if file.endswith('.WAV')]\n",
    "            for voice_sample in voice_samples:\n",
    "                voice_sample_path = os.path.join(current_dir, voice_sample)\n",
    "                signal, fs = sf.read(voice_sample_path)\n",
    "\n",
    "                # Pre-emphasize signal\n",
    "#                 signal_preemphasized = speechpy.processing.preemphasis(signal, cof=0.98)\n",
    "            \n",
    "#                 mfcc = speechpy.feature.mfcc(signal, sampling_frequency=fs, frame_length=0.025, frame_stride=0.01,\n",
    "#                                  num_filters=40, fft_length=256, low_frequency=0, high_frequency=None)\n",
    "\n",
    "                current_signals_list = []\n",
    "                current_labels_list = []\n",
    "                phoneme_transcript_path = os.path.join(current_dir, voice_sample)[:-3] + 'PHN'\n",
    "                f = open(phoneme_transcript_path, encoding='utf-8')\n",
    "                lines = f.readlines()\n",
    "                for line in lines:\n",
    "                    data = line.split(' ')\n",
    "                    phoneme_start_idx = int(data[0])\n",
    "                    phoneme_stop_idx = int(data[1])\n",
    "                    phoneme = data[2].strip()\n",
    "                    \n",
    "                    label = np.zeros(len(unique_keywords))\n",
    "                    for phoneme_pair in keywords_list:\n",
    "                        if phoneme_pair[1] == phoneme:\n",
    "                            phoneme = phoneme_pair[0]\n",
    "                            break\n",
    "                    label[unique_keywords.index(phoneme)] = 1\n",
    "                    \n",
    "                    for frame in signal[int(phoneme_start_idx):int(phoneme_stop_idx)]:\n",
    "                        current_signals_list.append(frame)\n",
    "                        current_labels_list.append(label)\n",
    "                        \n",
    "                for i in range(len(current_signals_list)):\n",
    "                    if i >= prev_frames and i < len(current_signals_list) - future_frames:\n",
    "#                         if i%100:\n",
    "#                             filename = f'./local_recordings/{unique_keywords[current_labels_list[i].tolist().index(1)]}-{datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")}.wav'\n",
    "#                             sf.write(filename, current_signals_list[i - prev_frames: i + future_frames + 1], 16000)\n",
    "                        signals_list.append(current_signals_list[i - prev_frames: i + future_frames + 1])\n",
    "                        labels_list.append(unique_keywords[current_labels_list[i].tolist().index(1)])\n",
    "                        \n",
    "    return fs, signals_list, labels_list\n",
    "\n",
    "fs, x_train_signal, y_train_signal = create_phoneme_dataset(testing_dir, 30*160, 10*160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da89b466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['h#', 'sh', 'ix', 'hv', 'eh', 'dcl', 'jh', 'ih', 'd', 'ah', 'kcl', 'k', 's', 'ux', 'q', 'en', 'gcl', 'g', 'r', 'w', 'ao', 'epi', 'dx', 'axr', 'l', 'y', 'uh', 'n', 'ae', 'm', 'oy', 'ax', 'dh', 'tcl', 'iy', 'v', 'f', 't', 'pcl', 'ow', 'hh', 'ch', 'bcl', 'b', 'aa', 'em', 'ng', 'ay', 'th', 'ax-h', 'ey', 'p', 'aw', 'er', 'nx', 'z', 'el', 'uw', 'pau', 'zh', 'eng'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_phoneme_signals.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67a6807d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['s', 's'], ['i', 'iy'], ['i', 'ih'], ['d', 'd'], ['h', 'hh'], ['e', 'eh'], ['e', 'ay'], ['ch', 'ch'], ['k', 'k'], ['n', 'n'], ['o', 'ow'], ['a', 'ah'], ['r', 'r'], ['v', 'v'], ['z', 'z'], ['silence', 'h#'], ['other', 'sh'], ['other', 'ix'], ['other', 'hv'], ['other', 'dcl'], ['other', 'jh'], ['other', 'kcl'], ['other', 'ux'], ['other', 'q'], ['other', 'en'], ['other', 'gcl'], ['other', 'g'], ['other', 'w'], ['other', 'ao'], ['other', 'epi'], ['other', 'dx'], ['other', 'axr'], ['other', 'l'], ['other', 'y'], ['other', 'uh'], ['other', 'ae'], ['other', 'm'], ['other', 'oy'], ['other', 'ax'], ['other', 'dh'], ['other', 'tcl'], ['other', 'f'], ['other', 't'], ['other', 'pcl'], ['other', 'bcl'], ['other', 'b'], ['other', 'aa'], ['other', 'em'], ['other', 'ng'], ['other', 'th'], ['other', 'ax-h'], ['other', 'ey'], ['other', 'p'], ['other', 'aw'], ['other', 'er'], ['other', 'nx'], ['other', 'el'], ['other', 'uw'], ['other', 'pau'], ['other', 'zh'], ['other', 'eng']] \n",
      "\n",
      "['s', 'i', 'd', 'h', 'e', 'ch', 'k', 'n', 'o', 'a', 'r', 'v', 'z', 'silence', 'other']\n"
     ]
    }
   ],
   "source": [
    "keywords_list = [\n",
    "    ['s', 's'],\n",
    "    ['i', 'iy'],\n",
    "    ['i', 'ih'],\n",
    "    ['d', 'd'],\n",
    "    ['h', 'hh'],\n",
    "    ['e', 'eh'],\n",
    "    ['e', 'ay'],\n",
    "    ['ch', 'ch'],\n",
    "    ['k', 'k'],\n",
    "    ['n', 'n'],\n",
    "    ['o', 'ow'],\n",
    "    ['a', 'ah'],\n",
    "    ['r', 'r'],\n",
    "    ['v', 'v'],\n",
    "    ['z', 'z'],\n",
    "    ['silence', 'h#'],\n",
    "]\n",
    "\n",
    "for key in training_phoneme_signals.keys():\n",
    "    found = False\n",
    "    for phoneme_pair in keywords_list:\n",
    "        if phoneme_pair[1] == key:\n",
    "            found = True\n",
    "        if found:\n",
    "            break\n",
    "    \n",
    "    if not found:\n",
    "        keywords_list.append(['other', key])\n",
    "print(keywords_list, '\\n')\n",
    "\n",
    "unique_keywords = []\n",
    "for phoneme_pair in keywords_list:\n",
    "    if phoneme_pair[0] not in unique_keywords:\n",
    "        unique_keywords.append(phoneme_pair[0])\n",
    "print(unique_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ddfab69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_signal_array(signal_array):\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, constrained_layout=True)\n",
    "    fig.supxlabel('Time')\n",
    "    fig.set_size_inches(15, 5)\n",
    "    ax.plot(signal_array)\n",
    "    \n",
    "def plot_pcolor(signal_array):\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, constrained_layout=True)\n",
    "    fig.supxlabel('Time')\n",
    "    fig.set_size_inches(15, 5)\n",
    "    ax.pcolor(signal_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "020ac432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcad76d99fc94efc989b3504bb0c4ed4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/61 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae22e7812ab448f589e9c7d65a98a3bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7475 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\miniconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:256: UserWarning: n_fft=2048 is too large for input signal of length=1693\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\miniconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:256: UserWarning: n_fft=2048 is too large for input signal of length=1544\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\miniconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:256: UserWarning: n_fft=2048 is too large for input signal of length=1507\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\miniconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:256: UserWarning: n_fft=2048 is too large for input signal of length=1030\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\miniconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:256: UserWarning: n_fft=2048 is too large for input signal of length=1032\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\miniconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:256: UserWarning: n_fft=2048 is too large for input signal of length=514\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\miniconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:256: UserWarning: n_fft=2048 is too large for input signal of length=351\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\miniconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:256: UserWarning: n_fft=2048 is too large for input signal of length=471\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\miniconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:256: UserWarning: n_fft=2048 is too large for input signal of length=449\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\miniconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:256: UserWarning: n_fft=2048 is too large for input signal of length=457\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\miniconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:256: UserWarning: n_fft=2048 is too large for input signal of length=1784\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\miniconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:256: UserWarning: n_fft=2048 is too large for input signal of length=2027\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\miniconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:256: UserWarning: n_fft=2048 is too large for input signal of length=1694\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\miniconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:256: UserWarning: n_fft=2048 is too large for input signal of length=1963\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\miniconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:256: UserWarning: n_fft=2048 is too large for input signal of length=970\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\miniconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:256: UserWarning: n_fft=2048 is too large for input signal of length=1128\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\miniconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:256: UserWarning: n_fft=2048 is too large for input signal of length=1795\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\miniconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:256: UserWarning: n_fft=2048 is too large for input signal of length=793\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\miniconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:256: UserWarning: n_fft=2048 is too large for input signal of length=1003\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\miniconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:256: UserWarning: n_fft=2048 is too large for input signal of length=1758\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\miniconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:256: UserWarning: n_fft=2048 is too large for input signal of length=1224\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\miniconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:256: UserWarning: n_fft=2048 is too large for input signal of length=1031\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\miniconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:256: UserWarning: n_fft=2048 is too large for input signal of length=1894\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\miniconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:256: UserWarning: n_fft=2048 is too large for input signal of length=1019\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\miniconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:256: UserWarning: n_fft=2048 is too large for input signal of length=1773\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\miniconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:256: UserWarning: n_fft=2048 is too large for input signal of length=1516\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\miniconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:256: UserWarning: n_fft=2048 is too large for input signal of length=1154\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\miniconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:256: UserWarning: n_fft=2048 is too large for input signal of length=2010\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\miniconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:256: UserWarning: n_fft=2048 is too large for input signal of length=1283\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\miniconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:256: UserWarning: n_fft=2048 is too large for input signal of length=1020\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\miniconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:256: UserWarning: n_fft=2048 is too large for input signal of length=1801\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\miniconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:256: UserWarning: n_fft=2048 is too large for input signal of length=639\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\miniconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:256: UserWarning: n_fft=2048 is too large for input signal of length=648\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\miniconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:256: UserWarning: n_fft=2048 is too large for input signal of length=1736\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\miniconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:256: UserWarning: n_fft=2048 is too large for input signal of length=899\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\miniconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:256: UserWarning: n_fft=2048 is too large for input signal of length=994\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\miniconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:256: UserWarning: n_fft=2048 is too large for input signal of length=885\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\miniconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:256: UserWarning: n_fft=2048 is too large for input signal of length=1478\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\miniconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:256: UserWarning: n_fft=2048 is too large for input signal of length=709\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\miniconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:256: UserWarning: n_fft=2048 is too large for input signal of length=902\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\miniconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:256: UserWarning: n_fft=2048 is too large for input signal of length=737\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\miniconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:256: UserWarning: n_fft=2048 is too large for input signal of length=1541\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\miniconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:256: UserWarning: n_fft=2048 is too large for input signal of length=973\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\miniconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:256: UserWarning: n_fft=2048 is too large for input signal of length=884\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\miniconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:256: UserWarning: n_fft=2048 is too large for input signal of length=723\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\miniconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:256: UserWarning: n_fft=2048 is too large for input signal of length=1114\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 26\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_augmentations):\n\u001b[0;32m     19\u001b[0m     \n\u001b[0;32m     20\u001b[0m     \u001b[38;5;66;03m# Apply random time-shifting\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     23\u001b[0m \n\u001b[0;32m     24\u001b[0m     \u001b[38;5;66;03m# Apply random time-stretching\u001b[39;00m\n\u001b[0;32m     25\u001b[0m     stretch_amt \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39muniform(stretch_min, stretch_max)\n\u001b[1;32m---> 26\u001b[0m     signal_stretched \u001b[38;5;241m=\u001b[39m \u001b[43mlibrosa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meffects\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtime_stretch\u001b[49m\u001b[43m(\u001b[49m\u001b[43msignal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstretch_amt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;66;03m# Apply random pitch-shifting\u001b[39;00m\n\u001b[0;32m     29\u001b[0m     pitch_shift_amt \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39muniform(\u001b[38;5;241m-\u001b[39mpitch_shift_max, pitch_shift_max)\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\librosa\\effects.py:245\u001b[0m, in \u001b[0;36mtime_stretch\u001b[1;34m(y, rate, **kwargs)\u001b[0m\n\u001b[0;32m    242\u001b[0m stft \u001b[38;5;241m=\u001b[39m core\u001b[38;5;241m.\u001b[39mstft(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    244\u001b[0m \u001b[38;5;66;03m# Stretch by phase vocoding\u001b[39;00m\n\u001b[1;32m--> 245\u001b[0m stft_stretch \u001b[38;5;241m=\u001b[39m \u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mphase_vocoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    246\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    247\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    248\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhop_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhop_length\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    249\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_fft\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn_fft\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    250\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;66;03m# Predict the length of y_stretch\u001b[39;00m\n\u001b[0;32m    253\u001b[0m len_stretch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mround\u001b[39m(y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m/\u001b[39m rate))\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:1454\u001b[0m, in \u001b[0;36mphase_vocoder\u001b[1;34m(D, rate, hop_length, n_fft)\u001b[0m\n\u001b[0;32m   1452\u001b[0m \u001b[38;5;66;03m# Weighting for linear magnitude interpolation\u001b[39;00m\n\u001b[0;32m   1453\u001b[0m alpha \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmod(step, \u001b[38;5;241m1.0\u001b[39m)\n\u001b[1;32m-> 1454\u001b[0m mag \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m alpha) \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mabs(columns[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m+\u001b[39m alpha \u001b[38;5;241m*\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mabs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1456\u001b[0m \u001b[38;5;66;03m# Store to output array\u001b[39;00m\n\u001b[0;32m   1457\u001b[0m d_stretch[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, t] \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mphasor(phase_acc, mag\u001b[38;5;241m=\u001b[39mmag)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_set = []\n",
    "label_set = []\n",
    "shift_max = 0.5\n",
    "stretch_min = 0.8\n",
    "stretch_max = 1.2\n",
    "pitch_shift_max = 2\n",
    "\n",
    "n_augmentations = 5\n",
    "fs = 16000\n",
    "\n",
    "for keyword in tqdm(keywords_list):\n",
    "    count = 0\n",
    "    phoneme = keyword[0]\n",
    "    keyword = keyword[1]\n",
    "    label = np.zeros(len(unique_keywords))\n",
    "    label[unique_keywords.index(phoneme)] = 1\n",
    "    for signal in tqdm(training_phoneme_signals[keyword]):\n",
    "        for i in range(n_augmentations):\n",
    "            \n",
    "            # Apply random time-shifting\n",
    "#             shift_amt = np.random.uniform(-shift_max, shift_max)\n",
    "#             signal_shifted = librosa.effects.time_shift(signal, fs, shift_amt)\n",
    "\n",
    "            # Apply random time-stretching\n",
    "            stretch_amt = np.random.uniform(stretch_min, stretch_max)\n",
    "            signal_stretched = librosa.effects.time_stretch(signal, rate=stretch_amt)\n",
    "\n",
    "            # Apply random pitch-shifting\n",
    "            pitch_shift_amt = np.random.uniform(-pitch_shift_max, pitch_shift_max)\n",
    "            signal_pitch_shifted = librosa.effects.pitch_shift(signal_stretched, sr=fs, n_steps=pitch_shift_amt)\n",
    "\n",
    "            sf.write(f'{i}.wav', signal_pitch_shifted, 16000, 'PCM_24')\n",
    "            \n",
    "        if signal.shape[0] < 256:\n",
    "            continue\n",
    "        try:\n",
    "            mfcc = speechpy.feature.mfcc(signal, sampling_frequency=fs, frame_length=0.020, frame_stride=0.01,\n",
    "                         num_filters=40, fft_length=256, low_frequency=0, high_frequency=None)\n",
    "            mfcc_cmvn = speechpy.processing.cmvnw(mfcc,win_size=301,variance_normalization=True)\n",
    "            \n",
    "            for frame in mfcc_cmvn:\n",
    "                training_set.append(frame)\n",
    "                label_set.append(label)\n",
    "                count += 1\n",
    "        except:\n",
    "            pass\n",
    "#         plot_pcolor(mfcc_cmvn.T)\n",
    "\n",
    "#         mfcc = speechpy.feature.mfcc(signal_test, sampling_frequency=fs_test, frame_length=0.020, frame_stride=0.01,\n",
    "#                      num_filters=40, fft_length=512, low_frequency=0, high_frequency=None)\n",
    "#         mfcc_cmvn = speechpy.processing.cmvnw(mfcc,win_size=301,variance_normalization=True)\n",
    "#         plot_pcolor(mfcc_cmvn[:200].T)\n",
    "\n",
    "#         break\n",
    "    break\n",
    "    \n",
    "    audio_list = []\n",
    "\n",
    "    print(keyword, count)\n",
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc87183",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c00d52b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import scipy\n",
    "import scipy.io.wavfile as wav\n",
    "import numpy as np\n",
    "import wave\n",
    "import matplotlib.pyplot as plt\n",
    "import noisereduce\n",
    "import speechpy\n",
    "import os\n",
    "from scipy.cluster.vq import vq, kmeans2, kmeans, whiten\n",
    "from scipy.spatial import distance\n",
    "from tqdm.notebook import tqdm\n",
    "from hmmlearn import hmm\n",
    "import ruptures as rpt\n",
    "from matplotlib.ticker import (MultipleLocator, AutoMinorLocator)\n",
    "import soundfile as sf\n",
    "import sounddevice as sd\n",
    "import pickle \n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "import random\n",
    "import pyaudio\n",
    "from scipy.io.wavfile import write\n",
    "from sklearn.utils import shuffle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dc9fabe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training phoneme signals hasn't been loaded yet\n",
      "testing phoneme signals hasn't been loaded yet\n"
     ]
    }
   ],
   "source": [
    "testing_dir = os.getcwd()\n",
    "testing_dir = os.path.join(testing_dir, '.\\\\TIMIT\\\\TEST')\n",
    "\n",
    "training_dir = os.getcwd()\n",
    "training_dir = os.path.join(training_dir, '.\\\\TIMIT\\\\TRAIN')\n",
    "\n",
    "\n",
    "\n",
    "def load_phoneme_dataset(working_dir):\n",
    "    phoneme_signals = {}\n",
    "    dialect_folders = os.listdir(working_dir)\n",
    "    for dialect_folder in tqdm(dialect_folders, leave=False):\n",
    "        voice_folders = os.listdir(os.path.join(working_dir, dialect_folder))\n",
    "        for voice_sample_folder in tqdm(voice_folders, leave=False):\n",
    "            current_dir = os.path.join(working_dir, dialect_folder)\n",
    "            current_dir = os.path.join(current_dir, voice_sample_folder)\n",
    "\n",
    "            voice_samples = [file for file in os.listdir(current_dir) if file.endswith('.WAV')]\n",
    "            for voice_sample in voice_samples:\n",
    "                voice_sample_path = os.path.join(current_dir, voice_sample)\n",
    "                signal, fs = sf.read(voice_sample_path)\n",
    "#                 signal = np.zeros_like(signal)\n",
    "#                 signal[40000] = 10\n",
    "#                 print(signal.shape)\n",
    "    \n",
    "                # Pre-emphasize signal\n",
    "                signal_preemphasized = speechpy.processing.preemphasis(signal, cof=0.98)\n",
    "\n",
    "                # FFT\n",
    "#                 frames = speechpy.processing.stack_frames(signal_preemphasized, sampling_frequency=fs, frame_length=0.02, frame_stride=0.01, zero_padding=True)\n",
    "#                 fft = speechpy.processing.fft_spectrum(frames, 256)\n",
    "    \n",
    "#                 fig, ax = plt.subplots(nrows=2, ncols=1, constrained_layout=True)\n",
    "#                 fig.supxlabel('Time')\n",
    "#                 fig.set_size_inches(15, 10)\n",
    "#                 ax[0].plot(signal_preemphasized)\n",
    "#                 ax[0].set_xlim(0, signal_preemphasized.shape[0])\n",
    "                \n",
    "#                 fig.colorbar(ax[1].pcolor(fft.T))\n",
    "                \n",
    "\n",
    "                phoneme_transcript_path = os.path.join(current_dir, voice_sample)[:-3] + 'PHN'\n",
    "                f = open(phoneme_transcript_path, encoding='utf-8')\n",
    "                lines = f.readlines()\n",
    "                for line in lines:\n",
    "                    data = line.split(' ')\n",
    "                    phoneme_start_idx = int(data[0])\n",
    "                    phoneme_stop_idx = int(data[1])\n",
    "                    phoneme = data[2].strip()\n",
    "                    \n",
    "#                     ax[0].axvline(x=phoneme_start_idx, color='red')\n",
    "#                     ax[1].axvline(x=phoneme_start_idx/160, color='red')\n",
    "                    \n",
    "                    phoneme_signal_preemphasized = signal_preemphasized[int(phoneme_start_idx):int(phoneme_stop_idx)]\n",
    "\n",
    "                \n",
    "                    if phoneme in phoneme_signals:\n",
    "#                         print(phoneme_fft)\n",
    "                        phoneme_signals[phoneme].append(phoneme_signal_preemphasized)\n",
    "                        \n",
    "                    else:\n",
    "                        phoneme_signals[phoneme] = []\n",
    "                        phoneme_signals[phoneme].append(phoneme_signal_preemphasized)\n",
    "#                     print(phoneme_signals[phoneme])\n",
    "    return fs, phoneme_signals\n",
    "\n",
    "try:\n",
    "    training_phoneme_signals\n",
    "except NameError:\n",
    "    print('training phoneme signals hasn\\'t been loaded yet')\n",
    "    try:\n",
    "        with open('training_phoneme_signals.pkl', 'rb') as handle:\n",
    "            training_phoneme_signals = pickle.load(handle)\n",
    "    except:\n",
    "        print('training_phoneme_signals.pkl not found, start loading dataset')\n",
    "        fs, training_phoneme_signals = load_phoneme_dataset(training_dir)\n",
    "        with open('training_phoneme_signals.pkl', 'wb') as handle:\n",
    "            pickle.dump(training_phoneme_signals, handle)\n",
    "            \n",
    "try:\n",
    "    testing_phoneme_signals\n",
    "except NameError:\n",
    "    print('testing phoneme signals hasn\\'t been loaded yet')\n",
    "    try:\n",
    "        with open('testing_phoneme_signals.pkl', 'rb') as handle:\n",
    "            testing_phoneme_signals = pickle.load(handle)\n",
    "    except:\n",
    "        print('testing_phoneme_signals.pkl not found, start loading dataset')\n",
    "        fs, testing_phoneme_signals = load_phoneme_dataset(testing_dir)\n",
    "        with open('testing_phoneme_signals.pkl', 'wb') as handle:\n",
    "            pickle.dump(testing_phoneme_signals, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a0a962f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['s', 's'], ['i', 'iy'], ['i', 'ih'], ['d', 'd'], ['h', 'hh'], ['e', 'eh'], ['e', 'ay'], ['ch', 'ch'], ['k', 'k'], ['n', 'n'], ['o', 'ow'], ['a', 'ah'], ['r', 'r'], ['v', 'v'], ['z', 'z'], ['silence', 'h#'], ['other', 'sh'], ['other', 'ix'], ['other', 'hv'], ['other', 'dcl'], ['other', 'jh'], ['other', 'kcl'], ['other', 'ux'], ['other', 'q'], ['other', 'en'], ['other', 'gcl'], ['other', 'g'], ['other', 'w'], ['other', 'ao'], ['other', 'epi'], ['other', 'dx'], ['other', 'axr'], ['other', 'l'], ['other', 'y'], ['other', 'uh'], ['other', 'ae'], ['other', 'm'], ['other', 'oy'], ['other', 'ax'], ['other', 'dh'], ['other', 'tcl'], ['other', 'f'], ['other', 't'], ['other', 'pcl'], ['other', 'bcl'], ['other', 'b'], ['other', 'aa'], ['other', 'em'], ['other', 'ng'], ['other', 'th'], ['other', 'ax-h'], ['other', 'ey'], ['other', 'p'], ['other', 'aw'], ['other', 'er'], ['other', 'nx'], ['other', 'el'], ['other', 'uw'], ['other', 'pau'], ['other', 'zh'], ['other', 'eng']] \n",
      "\n",
      "['s', 'i', 'd', 'h', 'e', 'ch', 'k', 'n', 'o', 'a', 'r', 'v', 'z', 'silence', 'other']\n"
     ]
    }
   ],
   "source": [
    "# words_list = [\n",
    "#     ['c', 's iy'],\n",
    "#     ['c', 's ih'],\n",
    "#     ['d', 'd iy'],\n",
    "#     ['d', 'd ih'],\n",
    "#     ['h', 'hh eh ch'],\n",
    "#     ['h', 'hh ey ch'],\n",
    "#     ['h', 'eh ch'],\n",
    "#     ['h', 'ey ch'],\n",
    "#     ['k', 'k eh'],\n",
    "#     ['k', 'k ey'],\n",
    "#     ['n', 'eh n'],\n",
    "#     ['o', 'ow'],\n",
    "#     ['r', 'ah'],\n",
    "#     ['r', 'ah r'],\n",
    "#     ['s', 'eh s'],\n",
    "#     ['v', 'v iy'],\n",
    "#     ['v', 'v ih'],\n",
    "#     ['z', 'z iy'],\n",
    "#     ['z', 'z ih'],\n",
    "#     ['z', 'z eh d'],\n",
    "#     ['z', 's eh d']\n",
    "# ]\n",
    "keywords_list = [\n",
    "    ['s', 's'],\n",
    "    ['i', 'iy'],\n",
    "    ['i', 'ih'],\n",
    "    ['d', 'd'],\n",
    "    ['h', 'hh'],\n",
    "    ['e', 'eh'],\n",
    "    ['e', 'ay'],\n",
    "    ['ch', 'ch'],\n",
    "    ['k', 'k'],\n",
    "    ['n', 'n'],\n",
    "    ['o', 'ow'],\n",
    "    ['a', 'ah'],\n",
    "    ['r', 'r'],\n",
    "    ['v', 'v'],\n",
    "    ['z', 'z'],\n",
    "    ['silence', 'h#'],\n",
    "]\n",
    "\n",
    "for key in training_phoneme_signals.keys():\n",
    "    found = False\n",
    "    for phoneme_pair in keywords_list:\n",
    "        if phoneme_pair[1] == key:\n",
    "            found = True\n",
    "        if found:\n",
    "            break\n",
    "    \n",
    "    if not found:\n",
    "        keywords_list.append(['other', key])\n",
    "print(keywords_list, '\\n')\n",
    "\n",
    "unique_keywords = []\n",
    "for phoneme_pair in keywords_list:\n",
    "    if phoneme_pair[0] not in unique_keywords:\n",
    "        unique_keywords.append(phoneme_pair[0])\n",
    "print(unique_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7e98acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_signal_array(signal_array):\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, constrained_layout=True)\n",
    "    fig.supxlabel('Time')\n",
    "    fig.set_size_inches(15, 5)\n",
    "    ax.plot(signal_array)\n",
    "    \n",
    "def plot_pcolor(signal_array):\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, constrained_layout=True)\n",
    "    fig.supxlabel('Time')\n",
    "    fig.set_size_inches(15, 5)\n",
    "    ax.pcolor(signal_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c40260a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set hasn't been loaded yet\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    training_set\n",
    "except NameError:\n",
    "    print('training set hasn\\'t been loaded yet')\n",
    "    try:\n",
    "        with open('training_set.pkl', 'rb') as handle:\n",
    "            training_set = pickle.load(handle)\n",
    "\n",
    "        with open('label_set.pkl', 'rb') as handle:\n",
    "            label_set = pickle.load(handle)\n",
    "    except:\n",
    "        print('Cannot find training_set.pkl, start creating new dataset')\n",
    "        training_set = []\n",
    "        label_set = []\n",
    "\n",
    "        signal_test, fs_test = sf.read('Recording.wav')\n",
    "        signal_test = np.asarray([x[0] for x in signal_test])\n",
    "        print(fs)\n",
    "        for keyword in tqdm(keywords_list):\n",
    "            count = 0\n",
    "            phoneme = keyword[0]\n",
    "            keyword = keyword[1]\n",
    "            label = np.zeros(len(unique_keywords))\n",
    "            label[unique_keywords.index(phoneme)] = 1\n",
    "            for signal in tqdm(training_phoneme_signals[keyword]):\n",
    "        #         print(signal[0], keyword)\n",
    "        #         print(signal.shape)\n",
    "        #         signal = training_phoneme_signals['s'][290]\n",
    "        #         signal = np.concatenate((training_phoneme_signals['h#'][0], signal))\n",
    "        #         signal = np.concatenate((signal,training_phoneme_signals['iy'][10]))\n",
    "        #         signal = np.concatenate((signal, training_phoneme_signals['h#'][0]))\n",
    "        #         plot_signal_array(signal)\n",
    "\n",
    "        #         write('test.wav', fs, signal.astype(np.float32))\n",
    "                if signal.shape[0] < 256:\n",
    "                    continue\n",
    "                try:\n",
    "                    mfcc = speechpy.feature.mfcc(signal, sampling_frequency=fs, frame_length=0.020, frame_stride=0.01,\n",
    "                                 num_filters=40, fft_length=256, low_frequency=0, high_frequency=None)\n",
    "            #         mfcc_cmvn = speechpy.processing.cmvnw(mfcc,win_size=301,variance_normalization=True)\n",
    "                    for frame in mfcc:\n",
    "                        training_set.append(frame)\n",
    "                        label_set.append(label)\n",
    "                        count += 1\n",
    "                except:\n",
    "                    pass\n",
    "        #         plot_pcolor(mfcc_cmvn.T)\n",
    "\n",
    "        #         mfcc = speechpy.feature.mfcc(signal_test, sampling_frequency=fs_test, frame_length=0.020, frame_stride=0.01,\n",
    "        #                      num_filters=40, fft_length=512, low_frequency=0, high_frequency=None)\n",
    "        #         mfcc_cmvn = speechpy.processing.cmvnw(mfcc,win_size=301,variance_normalization=True)\n",
    "        #         plot_pcolor(mfcc_cmvn[:200].T)\n",
    "\n",
    "        #         break\n",
    "        #     break\n",
    "            audio_list = []\n",
    "\n",
    "            print(keyword, count)\n",
    "        with open('training_set.pkl', 'wb') as handle:\n",
    "            pickle.dump(training_set, handle)\n",
    "\n",
    "        with open('label_set.pkl', 'wb') as handle:\n",
    "            pickle.dump(label_set, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a3fec3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "label_count = np.zeros(len(unique_keywords))\n",
    "print(label_set[1])\n",
    "for label in label_set:\n",
    "    label_count[label.tolist().index(1)] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a3fc09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset counts:\n",
      "s 65999\n",
      "i 73012\n",
      "d 1393\n",
      "h 3866\n",
      "e 54131\n",
      "ch 5086\n",
      "k 13571\n",
      "n 21277\n",
      "o 21593\n",
      "a 14798\n",
      "r 23485\n",
      "v 7156\n",
      "z 22262\n",
      "silence 155588\n",
      "other 504274\n"
     ]
    }
   ],
   "source": [
    "print('Dataset counts:')\n",
    "for x, y in zip(unique_keywords, label_count):\n",
    "    print (x, int(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27775879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d7be0b26d3042889419c95d3f642e20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function tqdm.__del__ at 0x00000219D68DBEB0>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\miniconda3\\lib\\site-packages\\tqdm\\std.py\", line 1162, in __del__\n",
      "    self.close()\n",
      "  File \"C:\\Users\\user\\miniconda3\\lib\\site-packages\\tqdm\\notebook.py\", line 281, in close\n",
      "    def close(self):\n",
      "KeyboardInterrupt: \n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "training_set, label_set = shuffle(training_set, label_set)\n",
    "\n",
    "def add_random_noise(signal):\n",
    "    percentage = 0.05\n",
    "    noise = np.random.normal(0, signal.std(), signal.size) * percentage\n",
    "    return signal + noise\n",
    "\n",
    "target_dataset_count = 20000\n",
    "balanced_training_set = []\n",
    "balanced_training_label = []\n",
    "for i, keyword in enumerate(tqdm(unique_keywords)):\n",
    "    count = 0\n",
    "    for j, label in enumerate(label_set):\n",
    "        if label.tolist().index(1) == i:\n",
    "            signal = training_set[j]\n",
    "            balanced_training_set.append(signal)\n",
    "            balanced_training_label.append(label_set[j])\n",
    "            count += 1\n",
    "        if count >= target_dataset_count:\n",
    "            break\n",
    "    if label_count[i] < target_dataset_count:\n",
    "        remaining_count = target_dataset_count - label_count[i]\n",
    "        idx = 0\n",
    "        while remaining_count > 0:\n",
    "            for j, label in enumerate(label_set):\n",
    "                if label.tolist().index(1) == i:\n",
    "                    signal = training_set[j]\n",
    "                    signal = add_random_noise(signal)\n",
    "                    balanced_training_set.append(signal)\n",
    "                    balanced_training_label.append(label_set[j])\n",
    "                    remaining_count -= 1\n",
    "                if remaining_count <= 0:\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e472c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_label_count = np.zeros(len(unique_keywords))\n",
    "for label in balanced_training_label:\n",
    "    balanced_label_count[label.tolist().index(1)] += 1\n",
    "    \n",
    "print('Dataset counts:')\n",
    "for x, y in zip(unique_keywords, balanced_label_count):\n",
    "    print (x, int(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d15b98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('20k_training_set.pkl', 'wb') as handle:\n",
    "    pickle.dump(balanced_training_set, handle)\n",
    "\n",
    "with open('20k_training_label_set.pkl', 'wb') as handle:\n",
    "    pickle.dump(balanced_training_label, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfbe3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    testing_set\n",
    "except NameError:\n",
    "    print('testing set hasn\\'t been loaded yet')\n",
    "    try:\n",
    "        with open('testing_set.pkl', 'rb') as handle:\n",
    "            testing_set = pickle.load(handle)\n",
    "\n",
    "        with open('testing_label_set.pkl', 'rb') as handle:\n",
    "            testing_label_set = pickle.load(handle)\n",
    "    except:\n",
    "        print('Cannot find testing_set.pkl, start creating new dataset')\n",
    "        testing_set = []\n",
    "        testing_label_set = []\n",
    "\n",
    "        signal_test, fs_test = sf.read('Recording.wav')\n",
    "        signal_test = np.asarray([x[0] for x in signal_test])\n",
    "        print(fs)\n",
    "        for keyword in tqdm(keywords_list):\n",
    "            count = 0\n",
    "            phoneme = keyword[0]\n",
    "            keyword = keyword[1]\n",
    "            label = np.zeros(len(unique_keywords))\n",
    "            label[unique_keywords.index(phoneme)] = 1\n",
    "            for signal in tqdm(testing_phoneme_signals[keyword]):\n",
    "        #         print(signal[0], keyword)\n",
    "        #         print(signal.shape)\n",
    "        #         signal = training_phoneme_signals['s'][290]\n",
    "        #         signal = np.concatenate((training_phoneme_signals['h#'][0], signal))\n",
    "        #         signal = np.concatenate((signal,training_phoneme_signals['iy'][10]))\n",
    "        #         signal = np.concatenate((signal, training_phoneme_signals['h#'][0]))\n",
    "        #         plot_signal_array(signal)\n",
    "\n",
    "        #         write('test.wav', fs, signal.astype(np.float32))\n",
    "                if signal.shape[0] < 256:\n",
    "                    continue\n",
    "                try:\n",
    "                    mfcc = speechpy.feature.mfcc(signal, sampling_frequency=fs, frame_length=0.020, frame_stride=0.01,\n",
    "                                 num_filters=40, fft_length=256, low_frequency=0, high_frequency=None)\n",
    "            #         mfcc_cmvn = speechpy.processing.cmvnw(mfcc,win_size=301,variance_normalization=True)\n",
    "                    for frame in mfcc:\n",
    "                        testing_set.append(frame)\n",
    "                        testing_label_set.append(label)\n",
    "                        count += 1\n",
    "                except:\n",
    "                    pass\n",
    "        #         plot_pcolor(mfcc_cmvn.T)\n",
    "\n",
    "        #         mfcc = speechpy.feature.mfcc(signal_test, sampling_frequency=fs_test, frame_length=0.020, frame_stride=0.01,\n",
    "        #                      num_filters=40, fft_length=512, low_frequency=0, high_frequency=None)\n",
    "        #         mfcc_cmvn = speechpy.processing.cmvnw(mfcc,win_size=301,variance_normalization=True)\n",
    "        #         plot_pcolor(mfcc_cmvn[:200].T)\n",
    "\n",
    "        #         break\n",
    "        #     break\n",
    "            audio_list = []\n",
    "\n",
    "            print(keyword, count)\n",
    "        with open('testing_set.pkl', 'wb') as handle:\n",
    "            pickle.dump(testing_set, handle)\n",
    "\n",
    "        with open('testing_label_set.pkl', 'wb') as handle:\n",
    "            pickle.dump(testing_label_set, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784ce478",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_label_count = np.zeros(len(unique_keywords))\n",
    "for label in testing_label_set:\n",
    "    testing_label_count[label.tolist().index(1)] += 1\n",
    "print('Dataset counts:')\n",
    "for x, y in zip(unique_keywords, testing_label_count):\n",
    "    print (x, int(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a906652e",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_set, testing_label_set = shuffle(testing_set, testing_label_set)\n",
    "\n",
    "target_dataset_count = 5000\n",
    "balanced_testing_set = []\n",
    "balanced_testing_label = []\n",
    "for i, keyword in enumerate(tqdm(unique_keywords)):\n",
    "    count = 0\n",
    "    for j, label in enumerate(testing_label_set):\n",
    "        if label.tolist().index(1) == i:\n",
    "            signal = testing_set[j]\n",
    "            balanced_testing_set.append(signal)\n",
    "            balanced_testing_label.append(testing_label_set[j])\n",
    "            count += 1\n",
    "        if count >= target_dataset_count:\n",
    "            break\n",
    "    if testing_label_count[i] < target_dataset_count:\n",
    "        remaining_count = target_dataset_count - testing_label_count[i]\n",
    "        idx = 0\n",
    "        while remaining_count > 0:\n",
    "            for j, label in enumerate(testing_label_set):\n",
    "                if label.tolist().index(1) == i:\n",
    "                    signal = testing_set[j]\n",
    "                    signal = add_random_noise(signal)\n",
    "                    balanced_testing_set.append(signal)\n",
    "                    balanced_testing_label.append(testing_label_set[j])\n",
    "                    remaining_count -= 1\n",
    "                if remaining_count <= 0:\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4183e7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_testing_label_count = np.zeros(len(unique_keywords))\n",
    "for label in balanced_testing_label:\n",
    "    balanced_testing_label_count[label.tolist().index(1)] += 1\n",
    "    \n",
    "print('Dataset counts:')\n",
    "for x, y in zip(unique_keywords, balanced_testing_label_count):\n",
    "    print (x, int(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b805cbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('5k_testing_set.pkl', 'wb') as handle:\n",
    "    pickle.dump(balanced_testing_set, handle)\n",
    "\n",
    "with open('5k_testing_label_set.pkl', 'wb') as handle:\n",
    "    pickle.dump(balanced_testing_label, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85bde64f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58a2b951948a4737899288ba3320b80b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fd8a148f1804abe801f6a51b9f0d366",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 63\u001b[0m\n\u001b[0;32m     59\u001b[0m                         labels_list\u001b[38;5;241m.\u001b[39mappend(unique_keywords[current_labels_list[i]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;241m1\u001b[39m)])\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fs, signals_list, labels_list\n\u001b[1;32m---> 63\u001b[0m fs, x_train_signal, y_train_signal \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_phoneme_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtesting_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[15], line 57\u001b[0m, in \u001b[0;36mcreate_phoneme_dataset\u001b[1;34m(working_dir, prev_frames, future_frames)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m100\u001b[39m:\n\u001b[0;32m     56\u001b[0m     filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./local_recordings/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mphoneme\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.wav\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 57\u001b[0m     \u001b[43msf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_signals_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mprev_frames\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfuture_frames\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m16000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m signals_list\u001b[38;5;241m.\u001b[39mappend(current_signals_list[i \u001b[38;5;241m-\u001b[39m prev_frames: i \u001b[38;5;241m+\u001b[39m future_frames \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     59\u001b[0m labels_list\u001b[38;5;241m.\u001b[39mappend(unique_keywords[current_labels_list[i]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;241m1\u001b[39m)])\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\soundfile.py:343\u001b[0m, in \u001b[0;36mwrite\u001b[1;34m(file, data, samplerate, subtype, endian, format, closefd)\u001b[0m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    342\u001b[0m     channels \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m--> 343\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mSoundFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msamplerate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    344\u001b[0m \u001b[43m               \u001b[49m\u001b[43msubtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendian\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosefd\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    345\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(data)\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\soundfile.py:658\u001b[0m, in \u001b[0;36mSoundFile.__init__\u001b[1;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[0;32m    655\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m=\u001b[39m mode\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info \u001b[38;5;241m=\u001b[39m _create_info_struct(file, mode, samplerate, channels,\n\u001b[0;32m    657\u001b[0m                                  \u001b[38;5;28mformat\u001b[39m, subtype, endian)\n\u001b[1;32m--> 658\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode_int\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosefd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    659\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mset\u001b[39m(mode)\u001b[38;5;241m.\u001b[39missuperset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseekable():\n\u001b[0;32m    660\u001b[0m     \u001b[38;5;66;03m# Move write position to 0 (like in Python file objects)\u001b[39;00m\n\u001b[0;32m    661\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\soundfile.py:1205\u001b[0m, in \u001b[0;36mSoundFile._open\u001b[1;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[0;32m   1203\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1204\u001b[0m             file \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39mencode(_sys\u001b[38;5;241m.\u001b[39mgetfilesystemencoding())\n\u001b[1;32m-> 1205\u001b[0m     file_ptr \u001b[38;5;241m=\u001b[39m \u001b[43mopenfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode_int\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_info\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1206\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(file, \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m   1207\u001b[0m     file_ptr \u001b[38;5;241m=\u001b[39m _snd\u001b[38;5;241m.\u001b[39msf_open_fd(file, mode_int, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info, closefd)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "testing_dir = os.getcwd()\n",
    "testing_dir = os.path.join(testing_dir, '.\\\\TIMIT\\\\TEST')\n",
    "\n",
    "training_dir = os.getcwd()\n",
    "training_dir = os.path.join(training_dir, '.\\\\TIMIT\\\\TRAIN')\n",
    "\n",
    "\n",
    "\n",
    "def create_phoneme_dataset(working_dir, prev_frames, future_frames):\n",
    "    signals_list = []\n",
    "    labels_list = []\n",
    "    dialect_folders = os.listdir(working_dir)\n",
    "    for dialect_folder in tqdm(dialect_folders, leave=False):\n",
    "        voice_folders = os.listdir(os.path.join(working_dir, dialect_folder))\n",
    "        for voice_sample_folder in tqdm(voice_folders, leave=False):\n",
    "            current_dir = os.path.join(working_dir, dialect_folder)\n",
    "            current_dir = os.path.join(current_dir, voice_sample_folder)\n",
    "\n",
    "            voice_samples = [file for file in os.listdir(current_dir) if file.endswith('.WAV')]\n",
    "            for voice_sample in voice_samples:\n",
    "                voice_sample_path = os.path.join(current_dir, voice_sample)\n",
    "                signal, fs = sf.read(voice_sample_path)\n",
    "\n",
    "                # Pre-emphasize signal\n",
    "#                 signal_preemphasized = speechpy.processing.preemphasis(signal, cof=0.98)\n",
    "            \n",
    "#                 mfcc = speechpy.feature.mfcc(signal, sampling_frequency=fs, frame_length=0.025, frame_stride=0.01,\n",
    "#                                  num_filters=40, fft_length=256, low_frequency=0, high_frequency=None)\n",
    "\n",
    "                current_signals_list = []\n",
    "                current_labels_list = []\n",
    "                phoneme_transcript_path = os.path.join(current_dir, voice_sample)[:-3] + 'PHN'\n",
    "                f = open(phoneme_transcript_path, encoding='utf-8')\n",
    "                lines = f.readlines()\n",
    "                for line in lines:\n",
    "                    data = line.split(' ')\n",
    "                    phoneme_start_idx = int(data[0])\n",
    "                    phoneme_stop_idx = int(data[1])\n",
    "                    phoneme = data[2].strip()\n",
    "                    \n",
    "                    label = np.zeros(len(unique_keywords))\n",
    "                    for phoneme_pair in keywords_list:\n",
    "                        if phoneme_pair[1] == phoneme:\n",
    "                            phoneme = phoneme_pair[0]\n",
    "                            break\n",
    "                    label[unique_keywords.index(phoneme)] = 1\n",
    "                    \n",
    "                    for frame in signal[int(phoneme_start_idx):int(phoneme_stop_idx)]:\n",
    "                        current_signals_list.append(frame)\n",
    "                        current_labels_list.append(label)\n",
    "                        \n",
    "                for i in range(len(current_signals_list)):\n",
    "                    if i >= prev_frames and i < len(current_signals_list) - future_frames:\n",
    "                        if i%100:\n",
    "                            filename = f'./local_recordings/{phoneme}-{datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")}.wav'\n",
    "                            sf.write(filename, current_signals_list[i - prev_frames: i + future_frames + 1], 16000)\n",
    "                        signals_list.append(current_signals_list[i - prev_frames: i + future_frames + 1])\n",
    "                        labels_list.append(unique_keywords[current_labels_list[i].tolist().index(1)])\n",
    "                        \n",
    "    return fs, signals_list, labels_list\n",
    "\n",
    "fs, x_train_signal, y_train_signal = create_phoneme_dataset(testing_dir, 30*160, 10*160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a9fe0e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset counts:\n",
      "s 28706\n",
      "i 34923\n",
      "d 2314\n",
      "h 1566\n",
      "e 24015\n",
      "ch 2127\n",
      "k 7767\n",
      "n 12898\n",
      "o 7824\n",
      "a 7466\n",
      "r 15093\n",
      "v 4077\n",
      "z 10830\n",
      "silence 17679\n",
      "other 268242\n"
     ]
    }
   ],
   "source": [
    "label_count = np.zeros(len(unique_keywords))\n",
    "for label in y_train:\n",
    "    label_count[label.tolist().index(1)] += 1\n",
    "    \n",
    "print('Dataset counts:')\n",
    "for x, y in zip(unique_keywords, label_count):\n",
    "    print (x, int(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "959ceeb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "302687633856495681f40011c0d89b61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def add_random_noise(signal):\n",
    "    percentage = 0.05\n",
    "    noise = np.random.normal(0, signal.std(), signal.shape) * percentage\n",
    "    return signal + noise\n",
    "\n",
    "x_train, y_train = shuffle(x_train, y_train)\n",
    "\n",
    "target_dataset_count = 10000\n",
    "x_train_balanced = []\n",
    "y_train_balanced = []\n",
    "for i, keyword in enumerate(tqdm(unique_keywords)):\n",
    "    count = 0\n",
    "    for j, label in enumerate(y_train):\n",
    "        if label.tolist().index(1) == i:\n",
    "            x_train_balanced.append(np.array(x_train[j]))\n",
    "            y_train_balanced.append(np.array(y_train[j]))\n",
    "            count += 1\n",
    "        if count >= target_dataset_count:\n",
    "            break\n",
    "    if label_count[i] < target_dataset_count:\n",
    "        remaining_count = target_dataset_count - label_count[i]\n",
    "        idx = 0\n",
    "        while remaining_count > 0:\n",
    "            for j, label in enumerate(y_train):\n",
    "                if label.tolist().index(1) == i:\n",
    "                    signal = x_train[j]\n",
    "                    signal = add_random_noise(np.array(signal))\n",
    "                    x_train_balanced.append(np.array(signal))\n",
    "                    y_train_balanced.append(np.array(y_train[j]))\n",
    "                    remaining_count -= 1\n",
    "                if remaining_count <= 0:\n",
    "                    break\n",
    "x_train_balanced = np.array(x_train_balanced)\n",
    "y_train_balanced = np.array(y_train_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "da55fe2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.save('150k_x_test.npy', x_train_balanced)\n",
    "np.save('150k_y_test.npy', y_train_balanced)\n",
    "\n",
    "plot_pcolor(x_train_balanced[7].T)\n",
    "y_train_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1753aa2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75000, 41, 13)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_balanced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e851cd4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
